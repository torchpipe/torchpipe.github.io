---
id: installation
title: 安装
type: explainer
---


# 安装
<!-- Installation and Quick Start -->



## 依赖项

| 依赖             | 版本                   | 备注                                                                                                                                          |
|------------------|:-----------------------|---------------------------------------------------------------------------------------------------------------------------------------------|
| `cuda`           | >= 11.0                | - 与PyTorch依赖的cuda版本必须一致（便于`torch.utils.cpp_extension`即时编译代码） <br />- 不再对CUDA 10.2的兼容进行测试。                         |
| `pytorch`        | >= 1.13.0              | - 对于`c++14/cuda-10.2/pytorch==1.10.2`不再进行兼容测试，然而通过简单修改，您可能仍可运行。                                                      |
| `opencv`(可选)   | 3.x, 4.x               | 至少包含 core, imgproc，imgcodecs 和 highgui 四个模块                                                                                          |
| `tensorrt`(可选) | >= 7.2<br /><= 8.6.1.5 | - tensorrt 7.0 动态输入下存在[内存泄漏](https://github.com/NVIDIA/TensorRT/issues/351)<br />- tensorrt 7.1 及以下无法直接int8化动态输入的模型 |

:::note 
以上依赖项均来源于默认存在的特定计算后端。构筑c++核心不依赖于以上任意一项。
:::

## 使用NGC基础镜像 {#NGC}
最简单的方式是可以选择<font color='Brown'>NGC镜像</font>进行源码编译（低版本驱动依靠 Forward Compatibility 或者 Minor Version Compatibility 依然可能跑起来官方镜像）。
首先，克隆代码：

```bash
git clone -b master ssh://git@g.hz.netease.com:22222/deploy/torchpipe.git
# git clone -b master https://g.hz.netease.com/deploy/torchpipe.git
cd torchpipe/ && git submodule update --init --recursive
```

然后，启动容器，如果您的机器支持更高版本镜像，可采用[更新版本的Pytorch镜像](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags)。

```bash
img_name=nvcr.io/nvidia/pytorch:22.12-py3 #  for cuda11
# img_name=nvcr.io/nvidia/pytorch:23.05-py3 #  for tensort8.6.1, LayerNorm
docker run --rm --gpus=all  --network=host   --ulimit memlock=-1 --ulimit stack=67108864 -v `pwd`:/workspace  --privileged=true -it $img_name /bin/bash
```

:::note
- 如果您使用的是Transformer-like的模型，强烈推荐使用Tensorrt >= 8.6.1(`nvcr.io/nvidia/pytorch:23.05-py3`)以便支持 opset 17 for LayerNormalization 和 opset 18 GroupNormalization, 以及对此类模型更深的支持。然而，其NGC镜像对显卡驱动版本[有所要求](https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/rel-23-05.html#rel-23-05). 
可以使用下一节[自定义镜像](#selfdocker).
- 由于tensorrt的优化问题，部分较大参数量的Transformer-like的模型opset13下速度更快。


:::

接着，可以编译源代码：

<Tabs groupId="pip"  className="unique-tabs">
<TabItem value="sys" label="安装到系统">

```bash
python setup.py install
```
</TabItem>

<TabItem value="editable" label="可编辑模式">

```bash
pip install -e .
```

</TabItem>
<TabItem value="whl" label="打包">

```bash
python setup.py bdist_wheel
# 生成的.whl文件可以在同镜像的不同容器中使用：
pip install --upgrade dist/*.whl
```
</TabItem>
</Tabs>

然后，就可以跑所有示例代码了：

```bash
cd examples/resnet18 && python resnet18.py
# or 
cd examples/yolox && python yolox.py 
```

<details><summary>resnet18的并行推理</summary>

> 获取恰当的模型文件(目前支持 onnx, trt engine等).

```python
import torchvision.models as models
resnet18 = models.resnet18(pretrained=True).eval().cuda()

import tempfile, os, torch
model_path =  os.path.join(tempfile.gettempdir(), "./resnet18.onnx") 
resnet18 = models.resnet18(pretrained=True).eval().cuda()
data_bchw = torch.rand((1, 3, 224, 224)).cuda()
print("export: ", model_path)
torch.onnx.export(resnet18, data_bchw, model_path,
                  opset_version=17,
                  do_constant_folding=True,
                  input_names=["in"], output_names=["out"],dynamic_axes={"in": {0: "x"},"out": {0: "x"}})

# os.system(f"onnxsim {model_path} {model_path}")
```
 
> 现在你可以并发调用单模型了。
```python
import torch, torchpipe
model = torchpipe.pipe({'model': model_path,
                        'backend': "Sequential[cvtColorTensor,TensorrtTensor,SyncTensor]", # 后端引擎， 可见overview章节的解释。
                        'instance_num': 2, 'batching_timeout': '5', # 实例数和超时时间
                        'max': 4, # 模型优化范围最大值，也可以为 '4x3x224x224'
                        'mean': '123.675, 116.28, 103.53',#255*"0.485, 0.456, 0.406"，
                        'std': '58.395, 57.120, 57.375', # 将融合进tensorrt网络中
                        'color': 'rgb'}) # cvtColorTensor后端的参数： 目标颜色空间顺序
data = torch.zeros((1, 3, 224, 224)) # or torch.from_numpy(...)
input = {"data": data, 'color': 'bgr'}
model(input)  # 可并发调用
# 使用 "result" 作为数据输出标识；当然，其他键值也可自定义写入
print(input["result"].shape)  # 失败则此键值一定不存在，即使输入时已经存在。
```

</details>


更多示例，参见[案例展示](./showcase/showcase.mdx).


## 自定义dockerfile {#selfdocker}
:::tip
如果您在netease内网，可使用预编译镜像(Pascal驱动>=510)：
```bash
docker pull hub.c.163.com/neteaseis/ai/torchpipe:base_trt-8.6
```
:::
参考[示例dockerfile](https://g.hz.netease.com/deploy/torchpipe/-/blob/master/docker/torchpipe.base)，预先下载tensorrt和opencv后可编译相关基础镜像。
```
# put TensorRT-8.6.1.6.Linux.x86_64-gnu.cuda-11.8.tar.gz into thirdparty/
wget https://codeload.github.com/opencv/opencv/zip/refs/tags/4.5.4 -O thirdparty/opencv-4.5.4.zip
# docker build --network=host -f docker/torchpipe.base -t hub.c.163.com/neteaseis/ai/torchpipe:base_trt-8.6 .

# docker run --rm   --network=host --gpus=all --ulimit memlock=-1 --ulimit stack=67108864 --privileged=true  -v `pwd`:/workspace -it hub.c.163.com/neteaseis/ai/torchpipe:base_trt-8.6  /bin/bash 

```
这种方式编译出的基础镜像比NGC pytorch镜像体积更小. 需要注意，其`_GLIBCXX_USE_CXX11_ABI==0`



## 说明

### 编译选项

| 选项               | 默认值 |                      说明                      |
|--------------------|:------:|:--------------------------------------------:|
| DEBUG              |   0    |               是否编译为调试模式               |
| WITH_OPENCV        |   1    |          是否编译依赖opencv的c++后端           |
| WITH_TENSORRT      |   1    |         是否编译依赖tensorrt的c++后端          |
| IPIPE_KEY(optinal) |   无   | str(length>=8)，使用加解密功能时，需要设置此密钥 |



### ABI
编译代码和依赖库的编译器需要与安装的`PyTorch`所使用的编译器ABI相容(ABI-compatible)。
在pytorch中，可通过如下方式查看：
```bash
python -c "import torch; print(torch._C._GLIBCXX_USE_CXX11_ABI)"
```
| 安装源                                                                       | _GLIBCXX_USE_CXX11_ABI |
|:-----------------------------------------------------------------------------|:----------------------:|
| [PyPI-PyTorch](https://pytorch.org/get-started/locally/)                     |           0            |
| [NGC-PyTorch](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) |           1            |
| [libtorch](https://pytorch.org/cppdocs/installing.html)                      |           1            |



### 编译集成第三方库(以ubuntu-opencv为例)

默认使用 apt-get install libopencv-dev 安装的opencv 满足`_GLIBCXX_USE_CXX11_ABI=1`， 其与 pypi 上的pytorch不能一起使用。通过对cmake添加`-D_GLIBCXX_USE_CXX11_ABI=0` 配置，可编译pypi相容的opencv.
<details><summary>编译指令</summary>

```bash
wget https://codeload.github.com/opencv/opencv/zip/refs/tags/4.5.4 -O opencv-4.5.4.zip

unzip opencv-4.5.4.zip && pip3 install cmake

cd opencv-4.5.4/ && \
sed -i '1a add_definitions(-D_GLIBCXX_USE_CXX11_ABI=0)' CMakeLists.txt  && \
      mkdir build && cd build && \
      cmake -D CMAKE_BUILD_TYPE=Release \
            -D BUILD_WITH_DEBUG_INFO=OFF \
            -D CMAKE_INSTALL_PREFIX=/usr/local/ \
            -D INSTALL_C_EXAMPLES=OFF \
            -D INSTALL_PYTHON_EXAMPLES=OFF \
            -DENABLE_NEON=OFF  \
            -D WITH_TBB=ON \
            -DBUILD_TBB=ON  \
            -DBUILD_WEBP=OFF \
            -D BUILD_ITT=OFF -D WITH_IPP=ON  \
            -D WITH_V4L=OFF \
            -D WITH_QT=OFF \
            -D WITH_OPENGL=OFF \
            -D BUILD_opencv_dnn=OFF \
            -DBUILD_opencv_java=OFF \
            -DBUILD_opencv_python2=OFF \
            -DBUILD_opencv_python3=ON \
            -D BUILD_NEW_PYTHON_SUPPORT=ON \
            -D BUILD_PYTHON_SUPPORT=ON \
            -D PYTHON_DEFAULT_EXECUTABLE=/usr/bin/python3 \
            -DBUILD_opencv_java_bindings_generator=OFF \
            -DBUILD_opencv_python_bindings_generator=ON \
            -D BUILD_EXAMPLES=OFF \
            -D WITH_OPENEXR=OFF \
            -DWITH_JPEG=ON  \
            -DBUILD_JPEG=ON\
            -D BUILD_JPEG_TURBO_DISABLE=OFF \
            -D BUILD_DOCS=OFF \
            -D BUILD_PERF_TESTS=OFF \
            -D BUILD_TESTS=OFF \
            -D BUILD_opencv_apps=OFF \
            -D BUILD_opencv_calib3d=OFF \
            -D BUILD_opencv_contrib=OFF \
            -D BUILD_opencv_features2d=OFF \
            -D BUILD_opencv_flann=OFF \
            -DBUILD_opencv_gapi=OFF \
            -D WITH_CUDA=OFF \
            -D WITH_CUDNN=OFF \
            -D OPENCV_DNN_CUDA=OFF \
            -D ENABLE_FAST_MATH=1 \
            -D WITH_CUBLAS=0 \
            -D BUILD_opencv_gpu=OFF \
            -D BUILD_opencv_ml=OFF \
            -D BUILD_opencv_nonfree=OFF \
            -D BUILD_opencv_objdetect=OFF \
            -D BUILD_opencv_photo=OFF \
            -D BUILD_opencv_stitching=OFF \
            -D BUILD_opencv_superres=OFF \
            -D BUILD_opencv_ts=OFF \
            -D BUILD_opencv_video=OFF \
            -D BUILD_videoio_plugins=OFF \
            -D BUILD_opencv_videostab=OFF \
            -DBUILD_EXAMPLES=OFF \
            -DBUILD_opencv_calib3d=OFF \
            -DBUILD_opencv_features2d=OFF\
            -DBUILD_opencv_flann=OFF\
            -DBUILD_opencv_ml=OFF\
            -DBUILD_opencv_videoio=OFF\
                .. && make -j4 && make install
```

</details>






import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';